#Summary: The project implemented Hybrid Long Short Term Memory (LSTM) to prognosticate the closing stock price on
#short intervals. The company for evaluation is Air Canada on (TSX), Canadian market.

# Wilfredo Tovar Hidalgo
#  School of Information Technology
#  Carleton University
#  Ottawa, Canada
#  wilfredotovarhidalgo@cmail.carleton.ca

#Importing the libraries required

import math
import pandas_datareader as web
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

#Employing stock results from January, 2012 to July, 2018.
df = web.DataReader('AAPL', data_source='yahoo', start='2012-01-01', end='2018-07-01')
#Show the data
df

#Illustration of dataset
df.shape

#Employing stock results from January, 2012 to July, 2018.
df = web.DataReader('AAPL', data_source='yahoo', start='2012-01-01', end='2018-07-01')
#Show the data
df

#Illustration of dataset
df.shape

#Visualization the closing price records
plt.figure(figsize=(12,6))
plt.title('Close Price History')
plt.plot(df['Close'])
plt.xlabel('Date',fontsize=12)
plt.ylabel('Price in CAD $ Canadian Dollar',fontsize=12)
plt.show()
#PROFESSOR HERE YOU CAN SEE THE CLOSING PRICES, IT MIUCH MORE BETTER USE DATA FROM PREVIOUS YEARS SINCE IN 2020 THE MARKET HAD TO STOP DUE TO SEVERAL

#Produce a new dataframe
data = df.filter(['Close'])

#Transforming the dataframe to a numpy array
# TIMESSCONVERSION()
dataset = data.values

#Obtain/Estimate the amount of rows to train the model
training_data_len = math.ceil(len(dataset) *.8)
training_data_len

#Scale the all of the data
TIMESSCONVERSION = MinMaxScaler(feature_range=(0, 1))
scaled_data = TIMESSCONVERSION.fit_transform(dataset)
scaled_data
#**********PROFESSOR AS YOU CAN SEE HERE IT HAVE TO SHOWS A RANGE OF VALUES BETWEEN 0 TO 1************

#Create the scaled training data set
train_data = scaled_data[0:training_data_len  , : ]
#NTIMESTEPS Split the data into x_train and y_train data sets
x_train=[]
y_train = []
for i in range(30,len(train_data)):
    x_train.append(train_data[i-30:i,0])
    y_train.append(train_data[i,0])
    if i<= 31:
        print(x_train)
        print(y_train)
        print()

#Convert x_train and y_train to numpy arrays
#Training
x_train, y_train = np.array(x_train), np.array(y_train)

#Reshape the data into the shape accepted by the LSTM
#WE NEED THIS BECAUSE LSTM EXPECT THE INPUT BE 3 DIMENSIONAL AND X_TRAIN IS TWO DIMENSIONAL
x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))
x_train.shape
#********Professor here below you can see one the transformation from a bidimentional data set to threedimentional******

#Building my model the LSTM network model: here you can see the LAYERS
model = Sequential()
model.add(LSTM(units=20, return_sequences=True, input_shape= (x_train.shape[1],1))) #THESE ARE THE LAYERS
model.add(LSTM(units=20, return_sequences=False))
model.add(Dense(units=15))
model.add(Dense(units=1))

#Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

#Train the model
#Professor this is the training process it may take time depending of the information that we use.
model.fit(x_train, y_train, batch_size=1, epochs=1)

#Formation of Testing data set
#It will be the scaling testing data set
test_data = scaled_data[training_data_len - 30: , : ]
#Create the x_test and y_test data sets
x_test = []
y_test =  dataset[training_data_len : , : ]
for i in range(30,len(test_data)):
    x_test.append(test_data[i-30:i,0])

#ADDITION REFINED TO BI-LSTM

#Convert x_test to a numpy array
x_test = np.array(x_test)

#Reshape the data into the shape accepted by the LSTM
#Professor AGAIN I had to reshape the data from bi to three dimensional to be supported by LSTM
x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))

#Getting the models predicted price values
#Professor to be clear: Here what i want is to obtain PREDICTIONS TO CONTAIN THE SAME VALUES AS A WIDE DATA SET,
# So It can predict on short time price and not only for time series like the traditional alg do.
forecasts = model.predict(x_test)
forecasts = TIMESSCONVERSION.inverse_transform(forecasts) #Undo scaling

#Calculate and Obtain the value
#Obtaining the root squared error
#So the value is pretty descent for prediction
rmse =np.sqrt(np.mean(((forecasts- y_test)**2)))
rmse

#Plot/Create the data for the graph
train = data[:training_data_len]
valid = data[training_data_len:]
valid['forecasts'] = forecasts

#Visualize the data
plt.figure(figsize=(16,8))
plt.title('Model')
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close price Canadian Dollar', fontsize=18)
plt.plot(train['Close'])
plt.plot(valid[['Close', 'forecasts']])
plt.legend(['Train', 'Val', 'forecasts'], loc='lower right')
plt.show()

#Illustrate the valid and predicted prices
valid

